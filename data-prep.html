<!DOCTYPE html>
<html>
  <head>
    <title>Preparing input data &middot; Spatial Microsimulation with R.</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link href="www/bootstrap.min.css" rel="stylesheet">
    <link href="www/highlight.css" rel="stylesheet">

    <link href='http://fonts.googleapis.com/css?family=Inconsolata:400,700'
      rel='stylesheet' type='text/css'>
  </head>

  <body>

    <div class="container">

      <div class="masthead">
        <ul class="nav nav-pills pull-right">
          <li class="dropdown">
            <a href="#" class="dropdown-toggle" data-toggle="dropdown">
              Table of contents<b class="caret"></b>
            </a>
            <ul class="dropdown-menu pull-right" role="menu">
              <li><a href="introduction.html">Introduction</a></li>
<li><a href="what-is-smsim.html">What is spatial microsimulation?</a></li>
<li><a href="SimpleWorld.html">SimpleWorld</a></li>
<li><a href="data-prep.html">Preparing input data</a></li>
<li><a href="smsim-in-R.html">Spatial microsimulation in R</a></li>
<li><a href="CakeMap.html">CakeMap</a></li>
<li><a href="smsim-for-abm.html">Spatial microsimulation for agent-based models</a></li>
<li><a href="additional.html">Additional tools and techniques</a></li>
<li><a href="appendix.html">Appendix</a></li>
<li><a href="glossary.html">Glossary</a></li>
<li><a href="references.html">References</a></li>

            </ul>
          </li>
        </ul>

        <h3 class="muted"><a href="http://robinlovelace.net/spatial-microsim-book/">Spatial Microsimulation with R</a> <small>by Robin Lovelace</small></h3>
        <hr>
      </div>

      <div class="row">
        <div class="col-sm-3" id="nav">
        <div class="well">
          Comming soon as a physical book</a>.
        </div>

        <h4>Contents</h4>
          <ul class="list-unstyled" id="toc"></ul>

          <hr>
          <!--<p><a href="/contribute.html">How to contribute</a></p>-->

          <p><a class="btn btn-primary" href="https://github.com/RobinLovelace/spatial-microsim-book/edit/master/data-prep.Rmd">Edit this page</a></p>
        </div>

        <div id="content" class="col-sm-8 pull-right">
          <h1 id="DataPrep">Preparing input data</h1>
<p>This chapter focuses on the input datasets needed for spatial microsimulation. Correctly loading, manipulating and assessing these datasets will be critical to the performance of your models and the ease of modifying them to include new inputs. Fortunately R is an accomplished tool for data cleaning (Kabacoff, 2011) (<a href="http://www.manning.com/kabacoff/">http://www.manning.com/kabacoff/</a>), as we shall see. This chapter also provides the basis for chapter we perform spatial microsimulation.</p>
<p>As with most spatial microsimulation models, this example consists of a non-geographical individual-level dataset and a series of geographical zones. The data used in this chapter (and the data for all other chapters) can be downloaded from the book’s GitHub repository (<a href="https://github.com/Robinlovelace/spatial-microsim-book">https://github.com/Robinlovelace/spatial-microsim-book</a>). From this page, click on the ‘Download ZIP’ button to the right of the page and extract the folder into a sensible place on your computer, such as the Desktop. From there, you will want to run R from the project’s root directory: open the folder in a file browser and double click on ‘spatial-microsim-book.Rproj’. This should cause RStudio to be opened at this location, with all the input data files easily accessible to R through <em>relative file paths</em>.</p>
<p>To ease reproducibility of the analysis when working with real data, it is recommended that the process begins with a copy of the <em>raw</em> dataset on one’s hard disc. Rather than modifying this file, modified (‘cleaned’) versions should be saved as separate files. This ensures that after any mistakes, one can always recover information that otherwise could have been lost and makes the project fully reproducible. In this chapter, however, a relatively clean and very tiny dataset from SimpleWorld is used. We will see in Chapter  how to deal with larger and more messy data. Here the focus is on the principles.</p>
<p>The process of loading, checking and preparing the input datasets for spatial microsimulation is generally a linear process, encapsulating the following stages:</p>
<ol style="list-style-type: decimal">
<li>Load original data</li>
<li>Remove excess information</li>
<li>Re-categorise individual-level data</li>
<li>Set variable and value names</li>
<li>‘Flatten’ individual-level data</li>
</ol>
<p>‘Stripping down’ the datasets so that they only contain the bare essential information will enable you to focus solely on the data that you are interested in. This is not covered in this chapter because the input datasets are already extremely bare and because the process should be obvious.</p>
<p>We start with the individual-level dataset for a reason: this dataset is often more problematic to format than the constraint variables, so it is worth becoming acquainted with it at the outset. Of course, it is possible that the data you have are not suitable for spatial microsimulation because they lack sufficient constraint variables with shared categories in both individual and aggregate level tables. We assume that you have already checked this. The checking process for the datasets used in this chapter is simple: both aggregate and individual-level tables contain age and sex, so they can by combined. Let us proceed to load some data saved on our hard disc into R’s <em>environment</em>, where it is available in memory.</p>
<h2 id="Loading">Loading input data</h2>
<p>Real-world individual-level data may be provided in a variety of formats but ultimately needs to be loaded into R as a <em>data frame</em> object.</p>
<p>In this case the dataset is loaded from a <code>.csv</code> file:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load the individual-level data</span>
ind &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;data/SimpleWorld/ind.csv&quot;</span>) 
<span class="kw">class</span>(ind) <span class="co"># verify the data type of the object</span>
<span class="co">#&gt; [1] &quot;data.frame&quot;</span>
ind <span class="co"># print the individual-level data</span>
<span class="co">#&gt;   id age sex</span>
<span class="co">#&gt; 1  1  59   m</span>
<span class="co">#&gt; 2  2  54   m</span>
<span class="co">#&gt; 3  3  35   m</span>
<span class="co">#&gt; 4  4  73   f</span>
<span class="co">#&gt; 5  5  49   f</span></code></pre>
<p>Constraint data are usually made available one variable at a time, so these are read in one file at a time:</p>
<pre class="sourceCode r"><code class="sourceCode r">con_age &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;data/SimpleWorld/age.csv&quot;</span>)
con_sex &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;data/SimpleWorld/sex.csv&quot;</span>)</code></pre>
<p>We have loaded the aggregate constraints. As with the individual level data, is worth inspecting each object to ensure that they make sense before continuing. Taking a look at <code>age_con</code>, we can see that this data set consists of 2 variables for 3 zones:</p>
<pre class="sourceCode r"><code class="sourceCode r">con_age
<span class="co">#&gt;   a0.49 a.50.</span>
<span class="co">#&gt; 1     8     4</span>
<span class="co">#&gt; 2     2     8</span>
<span class="co">#&gt; 3     7     4</span></code></pre>
<p>This tells us that there 12, 10 and 11 individuals in zones 1, 2 and 3, respectively, with different proportions of young and old people. Zone 2, for example, is heavily dominated by older people: there are 8 people over 50 whilst there are only 2 young people (under 49) in the zone.</p>
<p>Even at this stage there is a potential for errors to be introduced. A classic mistake with areal data is that the order in which zones are loaded changes from one table to the next. The constraint data should therefore come with some kind of <em>zone id</em>, an identifying code that will eventually allow the attribute data to be combined with polygon shapes in GIS software.</p>
<p>If we’re sure that the row numbers match between the age and sex tables (we are sure in this case), the next important test is to check that the total populations are equal for both sets of variables. Ideally both the <em>total</em> study area populations and <em>row totals</em> should match. If the <em>row totals</em> match, this is a very good sign that not only confirms that the zones are listed in the same order, but also that each variable is sampling from the same <em>population base</em>. These tests are conducted in the following lines of code:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(con_age)
<span class="co">#&gt; [1] 33</span>
<span class="kw">sum</span>(con_sex) 
<span class="co">#&gt; [1] 33</span>

<span class="kw">rowSums</span>(con_age)
<span class="co">#&gt; [1] 12 10 11</span>
<span class="kw">rowSums</span>(con_sex)
<span class="co">#&gt; [1] 12 10 11</span>
<span class="kw">rowSums</span>(con_age) ==<span class="st"> </span><span class="kw">rowSums</span>(con_sex)
<span class="co">#&gt; [1] TRUE TRUE TRUE</span></code></pre>
<p>The results of the previous operations are encouraging. The total population is the same for each constraint overall and for each area (row) for both constraints. If the total populations between constraint variables do not match (e.g. because the population bases are different) this is problematic. Appropriate steps to normalise the errant constraint variables are described in the CakeMap Chapter ().</p>
<h2>Subsetting to remove excess information</h2>
<p>In the above code, <code>data.frame</code> objects containing precisely the information required for the next stage were loaded. More often, superfluous information will need to be removed from the data and subsets taken. It is worth removing superfluous variables earl, to avoid over-complicating and slowing-down the analysis. For example, if <code>ind</code> had 100 variables of which only the 1st, 3rd and 4th were of interest (in that they match the constraint variables), the following command could be used to update the object. Only the relevant variables corresponding to columns (1, 3 and 4 in this case) are retained: <code>ind &lt;- ind[, c(1, 3, 4)]</code>. Alternatively, <code>ind$age &lt;- NULL</code> removes the age variable.</p>
<p>Although <code>ind</code> is small and simple it will behave in the same way as a much larger dataset, providing opportunities for testing subsetting syntax in R. It is common, for example, to take a subset of the working <em>population base</em>: those aged 16 and 74 in full-time employment. Methods for doing this are provided in Section .</p>
<h2>Re-cateorising individual-level variables</h2>
<p>Before transforming the individual-level dataset <code>ind</code> into a form that can be compared with the aggregate-level constraints, we must ensure that each dataset contains the same information. It can be more challenging to re-categorise individual-level variables than to re-name or combine aggregate-level variables, so the former should usually be set first. An obvious difference between the individual and aggregate versions of the <code>age</code> variable is that the former is of type <code>integer</code> whereas the latter is composed of discrete bins: 0 to 49 and 50+. We can categories the variable into these bins using <code>cut()</code>:<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Test binning the age variable</span>
<span class="kw">cut</span>(ind$age, <span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">49</span>, <span class="dv">120</span>))
<span class="co">#&gt; [1] (49,120] (49,120] (0,49]   (49,120] (0,49]  </span>
<span class="co">#&gt; Levels: (0,49] (49,120]</span></code></pre>
<p>If we wanted to change these category labels to something more readable, we can do this by adding another argument to the <code>cut</code> function:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Convert age into a categorical variable with user-chosen labels</span>
(ind$age &lt;-<span class="st"> </span><span class="kw">cut</span>(ind$age, <span class="dt">breaks =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">49</span>, <span class="dv">120</span>),
  <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;a0_49&quot;</span>, <span class="st">&quot;a50+&quot;</span>)))
<span class="co">#&gt; [1] a50+  a50+  a0_49 a50+  a0_49</span>
<span class="co">#&gt; Levels: a0_49 a50+</span></code></pre>
<p>Users should be ware that <code>cut</code> results in a vector of class <em>factor</em>, which can cause problems later down the line.</p>
<h2>Matching individual and aggregate level data names</h2>
<p>Before combining the newly recategorised individual-level data with the aggregate constraints, it is useful to for the category labels to match up. This may seem trivial, but will save time in the long run. Here is the problem:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">levels</span>(ind$age)
<span class="co">#&gt; [1] &quot;a0_49&quot; &quot;a50+&quot;</span>
<span class="kw">names</span>(con_age)
<span class="co">#&gt; [1] &quot;a0.49&quot; &quot;a.50.&quot;</span></code></pre>
<p>Note that the names are subtly different. To solve this issue, we can simply change the names of the constraint variable, assuming they are in the correct order:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">names</span>(con_age) &lt;-<span class="st"> </span><span class="kw">levels</span>(ind$age) <span class="co"># rename aggregate variables</span></code></pre>
<p>With both the age and sex constraint variable names now matching the category labels of the individual-level data, we can proceed to create a single constraint object we label <code>cons</code>. We do this with <code>cbind()</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r">cons &lt;-<span class="st"> </span><span class="kw">cbind</span>(con_age, con_sex)
cons[<span class="dv">1</span>:<span class="dv">2</span>, ] <span class="co"># display the constraints for the first two zones</span>
<span class="co">#&gt;   a0_49 a50+ m f</span>
<span class="co">#&gt; 1     8    4 6 6</span>
<span class="co">#&gt; 2     2    8 4 6</span></code></pre>
<h2>‘Flattening’ the individual level data</h2>
<p>We have made steps towards combining the individual and aggregate datasets and now only need to deal with 2 objects (<code>ind</code> and <code>cons</code>) which now share category and variable names. However, these datasets cannot possibly be compared because they are of different dimensions:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dim</span>(ind)
<span class="co">#&gt; [1] 5 3</span>
<span class="kw">dim</span>(cons)
<span class="co">#&gt; [1] 3 4</span></code></pre>
<p>The above code confirms this: we have one individual-level dataset comprising 5 individuals with 3 variables (2 of which are constraint variables and the other an ID) and one aggregate-level constraint table called <code>cons</code>, representing 3 zones with count data for 4 categories across 2 variables.</p>
<p>The dimensions of at least one of these objects must change before they can be easily compared. To do this we ‘flatten’ the individual-level dataset; this means increasing its width to match the constraint data. This is a two-stage process. First, <code>model.matrix()</code> is used to expand each variable into the number of columns as there are categories in each and assign. Knoblauch and Maloney (2012) provide a lengthier description of this which is available online, for free.</p>
<p>Second, <code>colSums()</code> is used to take the sum of each column.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a></p>
<pre class="sourceCode r"><code class="sourceCode r">cat_age &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(~<span class="st"> </span>ind$age -<span class="st"> </span><span class="dv">1</span>)
cat_sex &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(~<span class="st"> </span>ind$sex -<span class="st"> </span><span class="dv">1</span>)[, <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>)]

 <span class="co"># Combine age and sex category columns into single data frame</span>
(ind_cat &lt;-<span class="st"> </span><span class="kw">cbind</span>(cat_age, cat_sex)) <span class="co"># brackets -&gt; print result</span>
<span class="co">#&gt;   ind$agea0_49 ind$agea50+ ind$sexm ind$sexf</span>
<span class="co">#&gt; 1            0           1        1        0</span>
<span class="co">#&gt; 2            0           1        1        0</span>
<span class="co">#&gt; 3            1           0        1        0</span>
<span class="co">#&gt; 4            0           1        0        1</span>
<span class="co">#&gt; 5            1           0        0        1</span></code></pre>
<p>Note that second call to <code>model.matrix</code> is suffixed with <code>[, c(2, 1)]</code>. This is to swap the order of the columns: the column variables are produced from <code>model.matrix</code> is alphabetic, whereas the order in which the variables have been saved in the constraints object <code>cons</code> is <code>male</code> then <code>female</code>. Such subtleties can be hard to notice yet completely change one’s results so be warned: the output from <code>model.matrix</code> will not always be compatible with the constraint variables.</p>
<p>To check that the code worked properly, let’s count the number of individuals represented in the new <code>ind_cat</code> variable, using <code>colSums</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">colSums</span>(ind_cat) <span class="co"># view the aggregated version of ind</span>
<span class="co">#&gt; ind$agea0_49  ind$agea50+     ind$sexm     ind$sexf </span>
<span class="co">#&gt;            2            3            3            2</span>
ind_agg &lt;-<span class="st"> </span><span class="kw">colSums</span>(ind_cat) <span class="co"># save the result</span></code></pre>
<p>The sum of both age and sex variables is 5 (the total number of individuals): it worked! Looking at <code>ind_agg</code>, it is also clear that the object has the same ‘width’, or number of columns, <code>cons</code>. This means that the individual-level data can now be compared with the aggregate-level data. We can check this by inspecting each object (e.g. via <code>View(ind_agg)</code>). A more rigorous test is to see if <code>ind_agg</code> can be combined with <code>ind_agg</code>, using <code>rbind</code>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">rbind</span>(cons[<span class="dv">1</span>,], ind_agg) <span class="co"># test compatibility of ind_agg and cons</span>
<span class="co">#&gt;   a0_49 a50+ m f</span>
<span class="co">#&gt; 1     8    4 6 6</span>
<span class="co">#&gt; 2     2    3 3 2</span></code></pre>
<p>If no error message is displayed on you computer, the answer is yes. This shows us a direct comparison between the number of people in each category of the constraint variables in zone and and in the individual level dataset overall. Clearly, the fit is not very good, with only 5 individuals in total existing in <code>ind_agg</code> (the total for each constraint) and 12 in zone 1. We can measure the size of this difference using measures of <em>goodnes of fit</em>. A simple measure is total absolute error (TAE), calculated in this case as <code>sum(abs(cons[1,] - ind_agg))</code>: the sum of the positive differences between cell values in the individual and aggregate level data.</p>
<p>The purpose of the <em>reweighting</em> procedure in spatial microsimulation is to minimise this difference (as measured in TAE above) by adding high weights to the most representative individuals.</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>The combination of curved and square brackets in the output may seem strange but this is in fact an International Standard - see <a href="http://en.wikipedia.org/wiki/ISO_31-11">http://en.wikipedia.org/wiki/ISO_31-11</a> for more information.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>As we shall see in Section , only the former of these is needed if we use the <strong>ipfp</strong> package for re-weighting the data, but both are presented to enable a better understanding of how IPF works.<a href="#fnref2">↩</a></p></li>
</ol>
</div>

        </div>
      </div>

      <div class="footer">
        <hr>
        <p>&copy; Site design: Hadley Wickham. Powered by <a href="http://jekyllrb.com/">jekyll</a>,
          <a href="http://yihui.name/knitr/">knitr</a>, and
          <a href="http://johnmacfarlane.net/pandoc/">pandoc</a>. Source
          available on <a href="https://github.com/robinlovelace/spatial-microsim-book/">github</a>.
        </p>
      </div>

    </div> <!-- /container -->

  <script src="//code.jquery.com/jquery.js"></script>
  <script src="www/bootstrap.min.js"></script>
  <script src="www/toc.js"></script>
  </body>
</html>
